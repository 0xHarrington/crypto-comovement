{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Nwe5ZSend9L"
   },
   "source": [
    "# Cryptocurrency Analysis: Latent Space Dependence\n",
    "### Ali Habibnia and Matt Harrington\n",
    "\n",
    "---\n",
    "\n",
    "**Goals**:\n",
    "1. Grab all relevant coins (defined by subsets in `subsets.py`, default = `top_50`)\n",
    "1. Fit benchmark latent variable models \n",
    "    1. AR(1)\n",
    "    2. SARIMA\n",
    "1. Grenerate Latent Features with Encoding Methods\n",
    "    1. Vanilla AE\n",
    "    2. Variational AE\n",
    "    3. Transformer (?)\n",
    "1. Pass latent features to predictive models\n",
    "    1. OLS\n",
    "    2. RNN\n",
    "    3. LSTM\n",
    "    4. Forecasting Transformer\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "laGCI_NGgYZF"
   },
   "source": [
    "## Plumbing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3bFRBuAgi12G",
    "outputId": "bce65757-2766-4815-9b8e-72d66686f667"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import importlib\n",
    "is_colab = importlib.util.find_spec(\"google\")\n",
    "found = is_colab is not None\n",
    "\n",
    "import_path = ''\n",
    "if found:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive/', force_remount=True)\n",
    "    import_path += '/content/gdrive/My Drive/Thesis/pairs/'\n",
    "\n",
    "else:\n",
    "    import_path += 'pairs/'\n",
    "\n",
    "print(import_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subsets import *\n",
    "from coin_helpers import load_coins, simplify\n",
    "returns = load_coins(import_path, top_50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ej_k8m2zxp__"
   },
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kXAwyNJERnyt"
   },
   "outputs": [],
   "source": [
    "# N = number of return periods\n",
    "def annualised_sharpe(returns, N=252):\n",
    "    return np.sqrt(N) * (returns.mean() / returns.std())\n",
    "\n",
    "def multi_get_rolling_samples(ts, lag = 12):\n",
    "    samples = []\n",
    "    fifth = round(len(ts.index) / 5)\n",
    "    for i in range(len(ts.index)):\n",
    "        if i >= lag:\n",
    "            if i % fifth == 0:\n",
    "                print(\"{} periods done\".format(i))\n",
    "            s = ts.iloc[i-lag: i]\n",
    "            samples.append(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8tTT2-31f77N"
   },
   "source": [
    "## Setting up import dictionary \"coins\", returns, and subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p03BY39DInW4"
   },
   "source": [
    "#### Subsetting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gVFBJFTpei2W"
   },
   "outputs": [],
   "source": [
    "hour_ret = simplify(returns, '1h')\n",
    "day_ret = simplify(returns, '1D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LebUOVrxkLF6",
    "outputId": "dd4eb506-182a-4496-af71-0c06f48b0b46"
   },
   "outputs": [],
   "source": [
    "n = 365\n",
    "twoyr, oneyr = [], []\n",
    "for c in day_ret.columns:\n",
    "    nulls = day_ret[c].isnull().sum()\n",
    "    lengs = day_ret[c].shape[0]\n",
    "    if lengs - nulls > n:\n",
    "        oneyr.append(c)\n",
    "        if lengs - nulls > 2*n:\n",
    "            twoyr.append(c)\n",
    "\n",
    "nyr = len(oneyr)\n",
    "nall = len(returns.columns)\n",
    "p = round(100 * nyr / nall, 2)\n",
    "print(\"{0} of {1} ({2}%) have more than {3} days of data\".format(nyr, nall, p, n))\n",
    "print(\"{0} of {1} ({2}%) have more than {3} days of data\".format(len(twoyr), nall, p, 2 * n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NVQhFZyR7utn"
   },
   "source": [
    "## Deep Learning Models\n",
    "\n",
    "###### Code based on [atcold/pytorch-deep-learning](https://github.com/Atcold/pytorch-Deep-Learning) on Github"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mk4KL4HHJxzB"
   },
   "source": [
    "#### Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hk7LBk8P5pPQ"
   },
   "outputs": [],
   "source": [
    "# standard \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import torch.nn.functional as fs\n",
    "\n",
    "# Pretty\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sm4MUZeMJ1N3"
   },
   "source": [
    "#### Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DGNVOAdb9Tsz"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "class CryptoReturnsDataset(Dataset):\n",
    "\n",
    "    def __init__(self, params, train = True):\n",
    "\n",
    "        # unpack extensiblee input tuple \n",
    "        ts, resample_period, lag, subset = params\n",
    "\n",
    "        raw = simplify(ts[subset], resample_period).dropna(0, 'any')\n",
    "        train_test_thresh = round((raw.shape[0] - lag) * .8) + lag\n",
    "        if train:\n",
    "            self.data = torch.tensor(raw.iloc[lag : train_test_thresh].values)\n",
    "        else:\n",
    "            self.data = torch.tensor(raw.iloc[train_test_thresh :].values)\n",
    "    \n",
    "        self.n_samples = self.data.shape[0] - lag\n",
    "        self.lag = lag\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index : index + self.lag]\n",
    "        d = x.shape[1]\n",
    "        x = x.reshape(-1, self.lag * d)\n",
    "        y = self.data[index + self.lag].reshape(-1)\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ik0EQaUWBDX"
   },
   "outputs": [],
   "source": [
    "# crypto_transforms = transforms.Compose([\n",
    "#     transforms.Resize(lag * len(subset)),\n",
    "#     transforms.ToTensor()\n",
    "# ])\n",
    "\n",
    "######## Dataset Parameters ########\n",
    "lag = 12\n",
    "subset = twoyr\n",
    "n_coins = len(subset)\n",
    "PARAMS = (returns,      # Returns df\n",
    "          '1h',         # Resample Frequency\n",
    "          lag,          # AR Lag\n",
    "          subset)       # Coin subset\n",
    "\n",
    "\n",
    "######## Data loader ########\n",
    "train_dataset = CryptoReturnsDataset(PARAMS, True)\n",
    "test_dataset = CryptoReturnsDataset(PARAMS, False)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = 128, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size = 1, shuffle=False)\n",
    "\n",
    "######## Device ########\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FS17z35VC8yZ"
   },
   "source": [
    "### Vanilla AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zxryssuDLTx-"
   },
   "outputs": [],
   "source": [
    "# Define standard AE model architecture and reconstruction loss\n",
    "\n",
    "ae_dim = 30  # for standard AE (under-complete hidden layer)\n",
    "# ae_dim = 500  # for denoising AE (over-complete hidden layer)\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(lag * n_coins, ae_dim),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(ae_dim, lag * n_coins),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VvPHD1ncnhxs"
   },
   "source": [
    "#### Training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NjxDYnBJC--u",
    "outputId": "11e0306b-1353-4054-b6fb-054c7ce3a78e"
   },
   "outputs": [],
   "source": [
    "epoch_jump = 100\n",
    "num_models = 3\n",
    "models = []\n",
    "ae_losses = []\n",
    "criterion = nn.MSELoss()\n",
    "learning_rate = 1e-3\n",
    "\n",
    "for mod in range(num_models):\n",
    "    ######## Model instantiation ########\n",
    "    model = Autoencoder().to(device)\n",
    "    models.append(model)\n",
    "\n",
    "    ######## Configure the optimiser ########  \n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=learning_rate,\n",
    "    )\n",
    "\n",
    "    num_epochs = epoch_jump * (mod + 1)\n",
    "    training_loss = np.zeros(num_epochs)\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, data in enumerate(train_loader):\n",
    "            x, _ = data\n",
    "            x = x.to(device)\n",
    "            x = x.view(x.size(0), -1)\n",
    "            \n",
    "            # =================== forward =====================\n",
    "            output = model(x)  # feed <x> (for std AE) or <x_bad> (for denoising AE)\n",
    "            loss = criterion(output, x.data)\n",
    "            \n",
    "            # =================== backward ====================\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # =================== log ========================\n",
    "        print(f'model [{mod + 1}], epoch [{epoch + 1}/{num_epochs}], loss: {loss.item():.9f}')\n",
    "        display.clear_output(wait=True)\n",
    "        \n",
    "        # =================== record ========================\n",
    "        training_loss[epoch] = loss.item()\n",
    "    ae_losses.append(training_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 500
    },
    "id": "5HitiSSVPX_j",
    "outputId": "06fbe19a-e52e-4b2d-e4e5-69fa52c967c2"
   },
   "outputs": [],
   "source": [
    "def plot_model_losses(losses):\n",
    "    fig=plt.figure(figsize=(12,8)) \n",
    "    for i, arr in enumerate(losses):\n",
    "        ne = len(arr)\n",
    "        plt.plot(arr, label=f'{ne}-epoch')\n",
    "    plt.title(f\"{len(losses[0])}-Jump Epoch Loss(es)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "plot_model_losses(ae_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OxS5_1acjmxe"
   },
   "source": [
    "#### Testing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cv4BAx7QonUI"
   },
   "outputs": [],
   "source": [
    "test_errors = []\n",
    "errs = [np.ones(len(test_dataset))] * num_models\n",
    "mags = np.ones(len(test_dataset))\n",
    "for mod in range(num_models):\n",
    "    model = models[mod]\n",
    "    for i, data in enumerate(test_loader):\n",
    "        x, _ = data\n",
    "        x = x.to(device)\n",
    "        flat_x = x.view(x.size(0), -1)\n",
    "        output = model(flat_x)\n",
    "        errs[mod][i] = torch.norm(output - flat_x, dim=1)\n",
    "        if mod == 0: \n",
    "            mags[i] = torch.norm(flat_x, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "n6dBw4rEtY1i",
    "outputId": "60745263-5fe2-460c-d302-ca433088098e"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,6))\n",
    "plt.hist(mags, bins=300, label='sample magnitude', alpha=.8)\n",
    "for i, err in enumerate(errs):\n",
    "    plt.hist(err, bins=300, label=f\"{(i+1)*epoch_jump}-Epoch\", alpha=.8 - (.1 * i))\n",
    "plt.grid(True)\n",
    "plt.title(\"# Epochs vs Error Magnitudes\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SuITOmGwjVvL"
   },
   "source": [
    "#### Latent AE Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ykggf7Yvjq2P"
   },
   "outputs": [],
   "source": [
    "errs = np.array(errs)\n",
    "errmeans = errs.mean(axis=1)\n",
    "best_index = np.where(errmeans == min(errmeans))[0][0]\n",
    "best_ae = models[best_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "07yb-yGujVII"
   },
   "outputs": [],
   "source": [
    "class AELatentDataset(Dataset):\n",
    "\n",
    "    def __init__(self, params = PARAMS, model = best_ae, train = True):\n",
    "\n",
    "        # unpack extensiblee input tuple \n",
    "        ts, resample_period, lag, subset = params\n",
    "\n",
    "        raw = simplify(ts[subset], resample_period).dropna(0, 'any')\n",
    "        train_test_thresh = round((raw.shape[0] - lag) * .8) + lag\n",
    "        if train:\n",
    "            self.data = torch.tensor(raw.iloc[lag : train_test_thresh].values)\n",
    "        else:\n",
    "            self.data = torch.tensor(raw.iloc[train_test_thresh :].values)\n",
    "    \n",
    "        self.n_samples = self.data.shape[0] - lag\n",
    "        self.lag = lag\n",
    "        self.ae = model\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index : index + self.lag]\n",
    "        d = x.shape[1]\n",
    "        x = x.reshape(-1, self.lag * d)\n",
    "        latent_x = torch.tensor(self.ae.encoder(x))\n",
    "        y = self.data[index + self.lag].reshape(-1)\n",
    "        return latent_x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "######## Data loader ########\n",
    "ae_latent_train_dataset = AELatentDataset(PARAMS, best_ae, train = True)\n",
    "ae_latent_test_dataset = AELatentDataset(PARAMS, best_ae, train = False)\n",
    "\n",
    "ae_latent_train_loader = DataLoader(ae_latent_train_dataset, \n",
    "                                    batch_size = 128, \n",
    "                                    shuffle=False)\n",
    "ae_latent_test_loader = DataLoader(ae_latent_test_dataset,\n",
    "                                   batch_size = 1,\n",
    "                                   shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uNmFjyLwDAvI"
   },
   "source": [
    "### Variational AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IHSnZ-b7LW7h"
   },
   "outputs": [],
   "source": [
    "# Defining the model\n",
    "\n",
    "d = 20\n",
    "in_dim = lag * n_coins\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(in_dim, d ** 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d ** 2, d * 2)\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(d, d ** 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d ** 2, in_dim),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def reparameterise(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = logvar.mul(0.5).exp_()\n",
    "            eps = std.data.new(std.size()).normal_()\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu_logvar = self.encoder(x.view(-1, in_dim)).view(-1, 2, d)\n",
    "        mu = mu_logvar[:, 0, :]\n",
    "        logvar = mu_logvar[:, 1, :]\n",
    "        z = self.reparameterise(mu, logvar)\n",
    "        return self.decoder(z), mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cexzVpQQKS06"
   },
   "outputs": [],
   "source": [
    "# Reconstruction + KL divergence losses summed over all elements and batch\n",
    "\n",
    "def loss_function(x_hat, x, mu, logvar):\n",
    "    BCE = nn.functional.binary_cross_entropy(\n",
    "        x_hat, x.view(-1, in_dim), reduction='sum'\n",
    "    )\n",
    "    KLD = 0.5 * torch.sum(logvar.exp() - logvar - 1 + mu.pow(2))\n",
    "\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M6JfSjIr5rvT",
    "outputId": "0e9d2124-edd1-4e07-b7e6-fb77e3851191"
   },
   "outputs": [],
   "source": [
    "# Training and testing the VAE\n",
    "\n",
    "codes = dict(μ=list(), logσ2=list(), y=list())\n",
    "epoch_jump = 5\n",
    "num_models = 4\n",
    "models = []\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "# Multi-model loop\n",
    "for mod in range(num_models):\n",
    "\n",
    "    ######## Model instantiation ########\n",
    "    model = VAE().to(device)\n",
    "    models.append(model)\n",
    "\n",
    "    num_epochs = epoch_jump * (mod + 1)\n",
    "    training_loss = np.zeros(num_epochs)\n",
    "    testing_loss = np.zeros(num_epochs + 1)\n",
    "   \n",
    "    for epoch in range(0, num_epochs + 1):\n",
    "    \n",
    "        # Training\n",
    "        if epoch > 0:  # test untrained net first\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            for x, _ in train_loader:\n",
    "                x = x.to(device)\n",
    "                # ===================forward=====================\n",
    "                x_hat, mu, logvar = model(x)\n",
    "                loss = loss_function(x_hat, x, mu, logvar)\n",
    "                train_loss += loss.item()\n",
    "                # ===================backward====================\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            # ===================log========================\n",
    "            avg_loss = train_loss / len(train_loader.dataset)\n",
    "            print(f'====> Model: {mod+1}, Epoch: {epoch}, Average loss: {avg_loss:.4f}')\n",
    "\n",
    "            training_loss[epoch-1] = avg_loss\n",
    "    \n",
    "        # Testing\n",
    "        means, logvars, labels = list(), list(), list()\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            test_loss = 0\n",
    "            for x, y in test_loader:\n",
    "                x = x.to(device)\n",
    "                # ===================forward=====================\n",
    "                x_hat, mu, logvar = model(x)\n",
    "                test_loss += loss_function(x_hat, x, mu, logvar).item()\n",
    "                # =====================log=======================\n",
    "                means.append(mu.detach())\n",
    "                logvars.append(logvar.detach())\n",
    "                labels.append(y.detach())\n",
    "        \n",
    "        # ===================log========================\n",
    "        codes['μ'].append(torch.cat(means))\n",
    "        codes['logσ2'].append(torch.cat(logvars))\n",
    "        codes['y'].append(torch.cat(labels))\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        print(f'====> Test set loss: {test_loss:.4f}')\n",
    "        testing_loss[epoch] = test_loss\n",
    "        display.clear_output(wait=True)\n",
    "    \n",
    "    train_losses.append(training_loss)\n",
    "    test_losses.append(testing_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 983
    },
    "id": "S4eejcB1picb",
    "outputId": "66958f72-77a3-4eab-8964-3a7bead290fe"
   },
   "outputs": [],
   "source": [
    "plot_model_losses(train_losses)\n",
    "plot_model_losses(test_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gqk1p3stdUX5"
   },
   "source": [
    "#### VAE Latent Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qIdGGkEBlwCl"
   },
   "outputs": [],
   "source": [
    "errs = np.array([np.mean(x) for x in train_losses])\n",
    "best_index = np.where(errs == min(errs))[0][0]\n",
    "best_vae = models[best_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3_MjtyZLdLeD"
   },
   "outputs": [],
   "source": [
    "class VAELatentDataset(Dataset):\n",
    "\n",
    "    def __init__(self, params = PARAMS, model = best_vae, train = True):\n",
    "\n",
    "        # unpack extensiblee input tuple \n",
    "        ts, resample_period, lag, subset = params\n",
    "\n",
    "        raw = simplify(ts[subset], resample_period).dropna(0, 'any')\n",
    "        train_test_thresh = round((raw.shape[0] - lag) * .8) + lag\n",
    "        if train:\n",
    "            self.data = torch.tensor(raw.iloc[lag : train_test_thresh].values)\n",
    "        else:\n",
    "            self.data = torch.tensor(raw.iloc[train_test_thresh :].values)\n",
    "    \n",
    "        self.n_samples = self.data.shape[0] - lag\n",
    "        self.lag = lag\n",
    "        self.vae = model\n",
    "        self.vae.eval()\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index : index + self.lag]\n",
    "        d = x.shape[1]\n",
    "        x = x.reshape(-1, self.lag * d)\n",
    "        _, mu, logvar = self.vae.forward(x)\n",
    "        latent_x = self.vae.reparameterise(x)\n",
    "        y = self.data[index + self.lag].reshape(-1)\n",
    "        return latent_x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "######## Data loader ########\n",
    "vae_latent_train_dataset = VAELatentDataset(PARAMS, best_vae, train = True)\n",
    "vae_latent_test_dataset = VAELatentDataset(PARAMS, best_vae, train = False)\n",
    "\n",
    "vae_latent_train_loader = DataLoader(vae_latent_train_dataset, \n",
    "                                     batch_size = 128, \n",
    "                                     shuffle=False)\n",
    "vae_latent_test_loader = DataLoader(vae_latent_test_dataset,\n",
    "                                    batch_size = 1,\n",
    "                                    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UtRxbk3Fih5t"
   },
   "source": [
    "## Baseline Predictive Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3IjQgOl0ivwe"
   },
   "outputs": [],
   "source": [
    "!pip install statsmodels\n",
    "import statsmodels as sm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UlCQkLdSL0zo"
   },
   "source": [
    "\n",
    "## Predictive Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "niqnSxqbiTQH",
    "outputId": "8e119e64-8295-4ca5-bfa4-1944f66db384"
   },
   "outputs": [],
   "source": [
    "######## AE Latent Dataset ########\n",
    "ae_latent_train_dataset, ae_latent_test_dataset\n",
    "ae_latent_train_loader, ae_latent_test_loader\n",
    "\n",
    "######## VAE Latent Dataset ########\n",
    "vae_latent_train_dataset, vae_latent_test_dataset\n",
    "vae_latent_train_loader, vae_latent_test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5P4851HJLYtL"
   },
   "outputs": [],
   "source": [
    "# Leverage helper function code to create rolling multivariate AR windows\n",
    "#   to serve as input for the AE models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IMq36ZC4MDez"
   },
   "outputs": [],
   "source": [
    "# grab / organize the latent outputs from the \n",
    "#   encoding models & prep for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UxIZPIaqMP_y"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "# warnings.filterwarnings(\"UserWarning\")\n",
    "\n",
    "# LSTM \n",
    "class SimpleLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.lstm = torch.nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.linear = torch.nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.lstm(x)[0]\n",
    "        x = self.linear(h)\n",
    "        return x\n",
    "    \n",
    "    def get_states_across_time(self, x):\n",
    "        h_c = None\n",
    "        h_list, c_list = list(), list()\n",
    "        with torch.no_grad():\n",
    "            for t in range(x.size(1)):\n",
    "                h_c = self.lstm(x[:, [t], :], h_c)[1]\n",
    "                h_list.append(h_c[0])\n",
    "                c_list.append(h_c[1])\n",
    "            h = torch.cat(h_list)\n",
    "            c = torch.cat(c_list)\n",
    "        return h, c\n",
    "\n",
    "def train(model, train_data_gen, criterion, optimizer, device):\n",
    "    # Set the model to training mode. This will turn on layers that would\n",
    "    # otherwise behave differently during evaluation, such as dropout.\n",
    "    model.train()\n",
    "\n",
    "    # Store the number of sequences that were classified correctly\n",
    "    num_correct = 0\n",
    "\n",
    "    # Iterate over every batch of sequences. Note that the length of a data generator\n",
    "    # is defined as the number of batches required to produce a total of roughly 1000\n",
    "    # sequences given a batch size.\n",
    "    for data, target in train_data_gen:\n",
    "\n",
    "        # Request a batch of sequences and class labels, convert them into tensors\n",
    "        # of the correct type, and then send them to the appropriate device.\n",
    "        # data, target = train_data_gen[batch_idx]\n",
    "        # data, target = torch.from_numpy(data).float().to(device), torch.from_numpy(target).long().to(device)\n",
    "        data, target = torch.tensor(data).float().to(device), torch.tensor(target).long().to(device)\n",
    "\n",
    "        # Perform the forward pass of the model\n",
    "        output = model(data)  # Step ①\n",
    "\n",
    "        # Pick only the output corresponding to last sequence element (input is pre padded)\n",
    "        output = output[:, -1, :]\n",
    "\n",
    "        # Compute the value of the loss for this batch. For loss functions like CrossEntropyLoss,\n",
    "        # the second argument is actually expected to be a tensor of class indices rather than\n",
    "        # one-hot encoded class labels. One approach is to take advantage of the one-hot encoding\n",
    "        # of the target and call argmax along its second dimension to create a tensor of shape\n",
    "        # (batch_size) containing the index of the class label that was hot for each sequence.\n",
    "        target = target.argmax(dim=1)\n",
    "\n",
    "        loss = criterion(output, target)  # Step ②\n",
    "\n",
    "        # Clear the gradient buffers of the optimized parameters.\n",
    "        # Otherwise, gradients from the previous batch would be accumulated.\n",
    "        optimizer.zero_grad()  # Step ③\n",
    "\n",
    "        loss.backward()  # Step ④\n",
    "\n",
    "        optimizer.step()  # Step ⑤\n",
    "\n",
    "        y_pred = output.argmax(dim=1)\n",
    "        num_correct += (y_pred == target).sum().item()\n",
    "\n",
    "    return num_correct, loss.item() \n",
    "\n",
    "def test(model, test_data_gen, criterion, device):\n",
    "    # Set the model to evaluation mode. This will turn off layers that would\n",
    "    # otherwise behave differently during training, such as dropout.\n",
    "    model.eval()\n",
    "\n",
    "    # Store the number of sequences that were classified correctly\n",
    "    num_correct = 0\n",
    "\n",
    "    # A context manager is used to disable gradient calculations during inference\n",
    "    # to reduce memory usage, as we typically don't need the gradients at this point.\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_data_gen:\n",
    "            data, target = torch.tensor(data).float().to(device), torch.tensor(target).long().to(device)\n",
    "\n",
    "            output = model(data)\n",
    "            # Pick only the output corresponding to last sequence element (input is pre padded)\n",
    "            output = output[:, -1, :]\n",
    "\n",
    "            target = target.argmax(dim=1)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            y_pred = output.argmax(dim=1)\n",
    "            num_correct += (y_pred == target).sum().item()\n",
    "\n",
    "    return num_correct, loss.item()\n",
    "\n",
    "def train_and_test(model, train_data_gen, test_data_gen, criterion, optimizer, max_epochs, verbose=True):\n",
    "    # Automatically determine the device that PyTorch should use for computation\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Move model to the device which will be used for train and test\n",
    "    model.to(device)\n",
    "\n",
    "    # Track the value of the loss function and model accuracy across epochs\n",
    "    history_train = {'loss': [], 'acc': []}\n",
    "    history_test = {'loss': [], 'acc': []}\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        # Run the training loop and calculate the accuracy.\n",
    "        # Remember that the length of a data generator is the number of batches,\n",
    "        # so we multiply it by the batch size to recover the total number of sequences.\n",
    "        num_correct, loss = train(model, train_data_gen, criterion, optimizer, device)\n",
    "        accuracy = float(num_correct) / (len(train_data_gen) * train_data_gen.batch_size) * 100\n",
    "        history_train['loss'].append(loss)\n",
    "        history_train['acc'].append(accuracy)\n",
    "\n",
    "        # Do the same for the testing loop\n",
    "        num_correct, loss = test(model, test_data_gen, criterion, device)\n",
    "        accuracy = float(num_correct) / (len(test_data_gen) * test_data_gen.batch_size) * 100\n",
    "        history_test['loss'].append(loss)\n",
    "        history_test['acc'].append(accuracy)\n",
    "\n",
    "        if verbose or epoch + 1 == max_epochs:\n",
    "            print(f'[Epoch {epoch + 1}/{max_epochs}]'\n",
    "                  f\" loss: {history_train['loss'][-1]:.4f}, acc: {history_train['acc'][-1]:2.2f}%\"\n",
    "                  f\" - test_loss: {history_test['loss'][-1]:.4f}, test_acc: {history_test['acc'][-1]:2.2f}%\")\n",
    "\n",
    "    # Generate diagnostic plots for the loss and accuracy\n",
    "    fig, axes = plt.subplots(ncols=2, figsize=(16, 8))\n",
    "    for ax, metric in zip(axes, ['loss', 'acc']):\n",
    "        ax.plot(history_train[metric])\n",
    "        ax.plot(history_test[metric])\n",
    "        ax.set_xlabel('epoch', fontsize=12)\n",
    "        ax.set_ylabel(metric, fontsize=12)\n",
    "        ax.legend(['Train', 'Test'], loc='best')\n",
    "    plt.show()\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "d-j4N5GofJ1n",
    "outputId": "2e594899-fa2b-4a11-9410-103b78341032"
   },
   "outputs": [],
   "source": [
    "# Setup the RNN and training settings\n",
    "input_size  = ae_dim\n",
    "hidden_size = 4\n",
    "output_size = n_coins\n",
    "model       = SimpleLSTM(input_size, hidden_size, output_size)\n",
    "criterion   = torch.nn.CrossEntropyLoss()\n",
    "optimizer   = torch.optim.RMSprop(model.parameters(), lr=0.001)\n",
    "max_epochs  = 4\n",
    "\n",
    "# Train the model\n",
    "model = train_and_test(model, ae_latent_train_loader, \n",
    "                       ae_latent_test_loader, criterion, \n",
    "                       optimizer, max_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fZJy8CA7MZge"
   },
   "outputs": [],
   "source": [
    "# LSTM - predicting latent representation with AR latent predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xuxCe8zo56DD"
   },
   "source": [
    "## Transformer Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xpi1uZqL6P_C"
   },
   "source": [
    "##### Multi-head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oO24sMXdL_4V"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, p, d_input=None):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        if d_input is None:\n",
    "            d_xq = d_xk = d_xv = d_model\n",
    "        else:\n",
    "            d_xq, d_xk, d_xv = d_input\n",
    "            \n",
    "        # Make sure that the embedding dimension of model is a multiple of number of heads\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.d_k = d_model // self.num_heads\n",
    "        \n",
    "        # These are still of dimension d_model. They will be split into number of heads \n",
    "        self.W_q = nn.Linear(d_xq, d_model, bias=False)\n",
    "        self.W_k = nn.Linear(d_xk, d_model, bias=False)\n",
    "        self.W_v = nn.Linear(d_xv, d_model, bias=False)\n",
    "        \n",
    "        # Outputs of all sub-layers need to be of dimension d_model\n",
    "        self.W_h = nn.Linear(d_model, d_model)\n",
    "        \n",
    "    def scaled_dot_product_attention(self, Q, K, V):\n",
    "        batch_size = Q.size(0) \n",
    "        k_length = K.size(-2) \n",
    "        \n",
    "        # Scaling by d_k so that the soft(arg)max doesnt saturate\n",
    "        Q = Q / np.sqrt(self.d_k)                         # (bs, n_heads, q_length, dim_per_head)\n",
    "        scores = torch.matmul(Q, K.transpose(2,3))          # (bs, n_heads, q_length, k_length)\n",
    "        \n",
    "        A = nn_Softargmax(dim=-1)(scores)   # (bs, n_heads, q_length, k_length)\n",
    "        \n",
    "        # Get the weighted average of the values\n",
    "        H = torch.matmul(A, V)     # (bs, n_heads, q_length, dim_per_head)\n",
    "\n",
    "        return H, A \n",
    "\n",
    "        \n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"\n",
    "        Split the last dimension into (heads X depth)\n",
    "        Return after transpose to put in shape (batch_size X num_heads X seq_length X d_k)\n",
    "        \"\"\"\n",
    "        return x.view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "\n",
    "    def group_heads(self, x, batch_size):\n",
    "        \"\"\"\n",
    "        Combine the heads again to get (batch_size X seq_length X (num_heads times d_k))\n",
    "        \"\"\"\n",
    "        return x.transpose(1, 2).contiguous().view(batch_size, -1, self.num_heads * self.d_k)\n",
    "    \n",
    "\n",
    "    def forward(self, X_q, X_k, X_v):\n",
    "        batch_size, seq_length, dim = X_q.size()\n",
    "\n",
    "        # After transforming, split into num_heads \n",
    "        Q = self.split_heads(self.W_q(X_q), batch_size)  # (bs, n_heads, q_length, dim_per_head)\n",
    "        K = self.split_heads(self.W_k(X_k), batch_size)  # (bs, n_heads, k_length, dim_per_head)\n",
    "        V = self.split_heads(self.W_v(X_v), batch_size)  # (bs, n_heads, v_length, dim_per_head)\n",
    "        \n",
    "        # Calculate the attention weights for each of the heads\n",
    "        H_cat, A = self.scaled_dot_product_attention(Q, K, V)\n",
    "        \n",
    "        # Put all the heads back together by concat\n",
    "        H_cat = self.group_heads(H_cat, batch_size)    # (bs, q_length, dim)\n",
    "        \n",
    "        # Final linear layer  \n",
    "        H = self.W_h(H_cat)          # (bs, q_length, dim)\n",
    "        \n",
    "        return H, A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0KcHmNn16gBQ"
   },
   "source": [
    "##### Convolutional Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yIKSGA4n6iyN"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, d_model, hidden_dim, p):\n",
    "        super().__init__()\n",
    "        self.k1convL1 = nn.Linear(d_model,    hidden_dim)\n",
    "        self.k1convL2 = nn.Linear(hidden_dim, d_model)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.k1convL1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.k1convL2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PwJzAv3n6Ttq"
   },
   "source": [
    "##### Transformer Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6-8ssHPJ6WSF"
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, conv_hidden_dim, p=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads, p)\n",
    "        self.cnn = CNN(d_model, conv_hidden_dim, p)\n",
    "\n",
    "        self.layernorm1 = nn.LayerNorm(normalized_shape=d_model, eps=1e-6)\n",
    "        self.layernorm2 = nn.LayerNorm(normalized_shape=d_model, eps=1e-6)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Multi-head attention \n",
    "        attn_output, _ = self.mha(x, x, x)  # (batch_size, input_seq_len, d_model)\n",
    "        \n",
    "        # Layer norm after adding the residual connection \n",
    "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "        \n",
    "        # Feed forward \n",
    "        cnn_output = self.cnn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "        \n",
    "        #Second layer norm after adding residual connection \n",
    "        out2 = self.layernorm2(out1 + cnn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        return out2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C8xmwelQ6yW1"
   },
   "source": [
    "Blocks of N Encoder Layers + Positional encoding + Input embedding\n",
    "\n",
    "Self attention by itself does not have any recurrence or convolutions so to make it sensitive to position we must provide additional positional encodings. These are calculated as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QUMJCAPf6tO8"
   },
   "outputs": [],
   "source": [
    "def create_sinusoidal_embeddings(nb_p, dim, E):\n",
    "    theta = np.array([\n",
    "        [p / np.power(10000, 2 * (j // 2) / dim) for j in range(dim)]\n",
    "        for p in range(nb_p)\n",
    "    ])\n",
    "    E[:, 0::2] = torch.FloatTensor(np.sin(theta[:, 0::2]))\n",
    "    E[:, 1::2] = torch.FloatTensor(np.cos(theta[:, 1::2]))\n",
    "    E.detach_()\n",
    "    E.requires_grad = False\n",
    "    E = E.to(device)\n",
    "\n",
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, d_model, vocab_size, max_position_embeddings, p):\n",
    "        super().__init__()\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, d_model, padding_idx=1)\n",
    "        self.position_embeddings = nn.Embedding(max_position_embeddings, d_model)\n",
    "        create_sinusoidal_embeddings(\n",
    "            nb_p=max_position_embeddings,\n",
    "            dim=d_model,\n",
    "            E=self.position_embeddings.weight\n",
    "        )\n",
    "\n",
    "        self.LayerNorm = nn.LayerNorm(d_model, eps=1e-12)\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        seq_length = input_ids.size(1)\n",
    "        position_ids = torch.arange(seq_length, dtype=torch.long, device=input_ids.device) # (max_seq_length)\n",
    "        position_ids = position_ids.unsqueeze(0).expand_as(input_ids)                      # (bs, max_seq_length)\n",
    "        \n",
    "        # Get word embeddings for each input id\n",
    "        word_embeddings = self.word_embeddings(input_ids)                   # (bs, max_seq_length, dim)\n",
    "        \n",
    "        # Get position embeddings for each position id \n",
    "        position_embeddings = self.position_embeddings(position_ids)        # (bs, max_seq_length, dim)\n",
    "        \n",
    "        # Add them both \n",
    "        embeddings = word_embeddings + position_embeddings  # (bs, max_seq_length, dim)\n",
    "        \n",
    "        # Layer norm \n",
    "        embeddings = self.LayerNorm(embeddings)             # (bs, max_seq_length, dim)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WsBVmqXQ6uCJ"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, num_layers, d_model, num_heads, ff_hidden_dim, input_vocab_size,\n",
    "               maximum_position_encoding, p=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = Embeddings(d_model, input_vocab_size,maximum_position_encoding, p)\n",
    "\n",
    "        self.enc_layers = nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            self.enc_layers.append(EncoderLayer(d_model, num_heads, ff_hidden_dim, p))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x) # Transform to (batch_size, input_seq_length, d_model)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x)\n",
    "\n",
    "        return x  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xPGaX1D26Wua"
   },
   "source": [
    "##### Transformer Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ukdlqqV6W4p"
   },
   "outputs": [],
   "source": [
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(self, num_layers, d_model, num_heads, conv_hidden_dim, input_vocab_size, num_answers):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, conv_hidden_dim, input_vocab_size,\n",
    "                         maximum_position_encoding=10000)\n",
    "        self.dense = nn.Linear(d_model, num_answers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        \n",
    "        x, _ = torch.max(x, dim=1)\n",
    "        x = self.dense(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QFewLlb27Iv2"
   },
   "outputs": [],
   "source": [
    "model = TransformerClassifier(num_layers=1, d_model=32, num_heads=2, \n",
    "                         conv_hidden_dim=128, input_vocab_size=50002, num_answers=2)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XB2fXCFA7GH1"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "epochs = 10\n",
    "t_total = len(train_loader) * epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wqXVUv3y7CwP"
   },
   "outputs": [],
   "source": [
    "def evaluate(data_loader):\n",
    "    data_iterator = iter(data_loader)\n",
    "    nb_batches = len(data_loader)\n",
    "    model.eval()\n",
    "    acc = 0 \n",
    "    for batch in data_iterator:\n",
    "        x = batch.text.to(device)\n",
    "        y = batch.label.to(device)\n",
    "                \n",
    "        out = model(x)\n",
    "        acc += (out.argmax(1) == y).cpu().numpy().mean()\n",
    "\n",
    "    print(f\"Eval accuracy: {acc / nb_batches}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kzSWO9wyMRiF"
   },
   "outputs": [],
   "source": [
    "# Transformer predictor?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "laGCI_NGgYZF",
    "Ej_k8m2zxp__",
    "8tTT2-31f77N",
    "CJJLVqe4Wdki",
    "DyDL1fhCgr99",
    "Djl0Em3IceWp",
    "gDRBbtJRUw9V",
    "IEfvvrzFVsbH",
    "FIZOucnMAcbl",
    "kH6IwlSJkHYQ",
    "A-PEJj74Ak6O",
    "W9AoQODtiHVm",
    "QeHSe0sOx_GC",
    "DHqZ24wwqCPL",
    "0PKxobpKI74z",
    "NVQhFZyR7utn",
    "Mk4KL4HHJxzB",
    "sm4MUZeMJ1N3",
    "UlCQkLdSL0zo",
    "xuxCe8zo56DD",
    "xpi1uZqL6P_C",
    "0KcHmNn16gBQ",
    "PwJzAv3n6Ttq",
    "xPGaX1D26Wua"
   ],
   "name": "Crypto Asset Analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:comovement] *",
   "language": "python",
   "name": "conda-env-comovement-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
